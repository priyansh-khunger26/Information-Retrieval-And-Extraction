{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9358214,"sourceType":"datasetVersion","datasetId":5673594}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-14T08:40:33.442381Z","iopub.execute_input":"2024-09-14T08:40:33.442889Z","iopub.status.idle":"2024-09-14T08:40:51.579912Z","shell.execute_reply.started":"2024-09-14T08:40:33.442828Z","shell.execute_reply":"2024-09-14T08:40:51.578548Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:40:51.582547Z","iopub.execute_input":"2024-09-14T08:40:51.582959Z","iopub.status.idle":"2024-09-14T08:40:53.268807Z","shell.execute_reply.started":"2024-09-14T08:40:51.582914Z","shell.execute_reply":"2024-09-14T08:40:53.267461Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\n# Download stopwords if you haven't already\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Initialize the Porter Stemmer\nstemmer = PorterStemmer()\n\n# Function to preprocess a document\ndef preprocess_document(text):\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove punctuations, special characters, and digits using regex\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    # Tokenize the text\n    tokens = word_tokenize(text)\n    \n    # Apply Porter Stemming to each token\n    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n    \n    return stemmed_tokens\n\n# Function to read documents from a directory\ndef preprocess_documents_from_directory(directory_path):\n    preprocessed_docs = []\n    \n    # Loop through all the files in the directory\n    for filename in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, filename)\n        \n        # Check if it's a file (ignore directories)\n        if os.path.isfile(file_path):\n            with open(file_path, 'r', encoding='utf-8') as file:\n                text = file.read()\n                preprocessed_text = preprocess_document(text)\n                \n                # Store the preprocessed tokens using the filename as key\n                preprocessed_docs.append(preprocessed_text)\n    \n    return preprocessed_docs\n\n# Path to your directory containing documents\ndirectory_path = '/kaggle/input/new-documents/documents'\n\n# Preprocess the documents\npreprocessed_documents = preprocess_documents_from_directory(directory_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T08:40:53.270378Z","iopub.execute_input":"2024-09-14T08:40:53.270944Z","iopub.status.idle":"2024-09-14T09:01:42.392361Z","shell.execute_reply.started":"2024-09-14T08:40:53.270898Z","shell.execute_reply":"2024-09-14T09:01:42.390714Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"preprocessed_documents[1]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:17:11.812197Z","iopub.execute_input":"2024-09-14T09:17:11.813366Z","iopub.status.idle":"2024-09-14T09:17:11.844597Z","shell.execute_reply.started":"2024-09-14T09:17:11.813298Z","shell.execute_reply":"2024-09-14T09:17:11.843009Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['thi',\n 'articl',\n 'is',\n 'more',\n 'than',\n 'month',\n 'old',\n 'thi',\n 'articl',\n 'is',\n 'more',\n 'than',\n 'month',\n 'old',\n 'tourist',\n 'attract',\n 'and',\n 'museum',\n 'in',\n 'central',\n 'pari',\n 'have',\n 'said',\n 'they',\n 'will',\n 'not',\n 'open',\n 'on',\n 'saturday',\n 'when',\n 'fresh',\n 'gilet',\n 'jaun',\n 'yellow',\n 'vest',\n 'protest',\n 'are',\n 'plan',\n 'as',\n 'french',\n 'author',\n 'prepar',\n 'to',\n 'deploy',\n 'secur',\n 'personnel',\n 'across',\n 'the',\n 'countri',\n 'the',\n 'demonstr',\n 'announc',\n 'on',\n 'saturday',\n 'decemb',\n 'in',\n 'pari',\n 'do',\n 'not',\n 'allow',\n 'us',\n 'to',\n 'welcom',\n 'visitor',\n 'in',\n 'safe',\n 'condit',\n 'said',\n 'the',\n 'oper',\n 'of',\n 'the',\n 'eiffel',\n 'tower',\n 'in',\n 'a',\n 'statement',\n 'on',\n 'thursday',\n 'polic',\n 'have',\n 'also',\n 'order',\n 'about',\n 'a',\n 'dozen',\n 'museum',\n 'includ',\n 'the',\n 'louvr',\n 'and',\n 'the',\n 'grand',\n 'palai',\n 'cultur',\n 'site',\n 'such',\n 'as',\n 'the',\n 'opera',\n 'and',\n 'shop',\n 'along',\n 'the',\n 'champslys',\n 'to',\n 'close',\n 'over',\n 'fear',\n 'of',\n 'violenc',\n 'we',\n 'can',\n 'not',\n 'take',\n 'the',\n 'risk',\n 'when',\n 'we',\n 'know',\n 'the',\n 'threat',\n 'franck',\n 'riester',\n 'the',\n 'cultur',\n 'minist',\n 'told',\n 'rtl',\n 'radio',\n 'sever',\n 'topleagu',\n 'footbal',\n 'match',\n 'have',\n 'also',\n 'been',\n 'cancel',\n 'as',\n 'senior',\n 'minist',\n 'sought',\n 'to',\n 'defus',\n 'public',\n 'furi',\n 'with',\n 'conciliatori',\n 'languag',\n 'on',\n 'tax',\n 'an',\n 'offici',\n 'in',\n 'emmanuel',\n 'macron',\n 'offic',\n 'risk',\n 'provok',\n 'more',\n 'anger',\n 'by',\n 'say',\n 'that',\n 'intellig',\n 'suggest',\n 'that',\n 'some',\n 'protest',\n 'would',\n 'come',\n 'to',\n 'the',\n 'capit',\n 'to',\n 'vandalis',\n 'and',\n 'to',\n 'kill',\n 'play',\n 'video',\n 'french',\n 'high',\n 'school',\n 'student',\n 'made',\n 'to',\n 'kneel',\n 'with',\n 'hand',\n 'on',\n 'head',\n 'by',\n 'polic',\n 'video',\n 'despit',\n 'capitul',\n 'thi',\n 'week',\n 'over',\n 'the',\n 'plan',\n 'for',\n 'higher',\n 'fuel',\n 'tax',\n 'that',\n 'inspir',\n 'the',\n 'nationwid',\n 'revolt',\n 'the',\n 'presid',\n 'ha',\n 'struggl',\n 'to',\n 'quell',\n 'the',\n 'anger',\n 'that',\n 'last',\n 'weekend',\n 'led',\n 'to',\n 'the',\n 'worst',\n 'street',\n 'unrest',\n 'in',\n 'central',\n 'pari',\n 'sinc',\n 'rioter',\n 'torch',\n 'car',\n 'vandalis',\n 'cafe',\n 'loot',\n 'shop',\n 'and',\n 'spray',\n 'antimacron',\n 'graffiti',\n 'across',\n 'some',\n 'of',\n 'pariss',\n 'most',\n 'affluent',\n 'district',\n 'even',\n 'defac',\n 'the',\n 'arc',\n 'de',\n 'triomph',\n 'score',\n 'of',\n 'peopl',\n 'were',\n 'hurt',\n 'and',\n 'hundr',\n 'arrest',\n 'in',\n 'battl',\n 'with',\n 'polic',\n 'macron',\n 'polit',\n 'look',\n 'to',\n 'blair',\n 'and',\n 'clinton',\n 'the',\n 'backlash',\n 'wa',\n 'inevit',\n 'larri',\n 'elliott',\n 'read',\n 'more',\n 'in',\n 'a',\n 'bid',\n 'to',\n 'end',\n 'the',\n 'threeweek',\n 'crisi',\n 'the',\n 'prime',\n 'minist',\n 'douard',\n 'philipp',\n 'told',\n 'parliament',\n 'late',\n 'on',\n 'wednesday',\n 'that',\n 'he',\n 'wa',\n 'scrap',\n 'the',\n 'fueltax',\n 'increas',\n 'plan',\n 'for',\n 'have',\n 'announc',\n 'a',\n 'sixmonth',\n 'suspens',\n 'the',\n 'day',\n 'befor',\n 'the',\n 'financ',\n 'minist',\n 'bruno',\n 'le',\n 'mair',\n 'told',\n 'a',\n 'confer',\n 'he',\n 'wa',\n 'prepar',\n 'to',\n 'bring',\n 'forward',\n 'taxcut',\n 'plan',\n 'and',\n 'that',\n 'he',\n 'want',\n 'worker',\n 'bonus',\n 'to',\n 'be',\n 'tax',\n 'free',\n 'but',\n 'he',\n 'ad',\n 'in',\n 'thi',\n 'case',\n 'it',\n 'must',\n 'go',\n 'handinhand',\n 'with',\n 'a',\n 'decreas',\n 'in',\n 'spend',\n 'he',\n 'also',\n 'said',\n 'franc',\n 'would',\n 'impos',\n 'a',\n 'tax',\n 'on',\n 'big',\n 'internet',\n 'firm',\n 'in',\n 'if',\n 'there',\n 'wa',\n 'no',\n 'consensu',\n 'on',\n 'an',\n 'euwid',\n 'levi',\n 'seek',\n 'to',\n 'appeal',\n 'to',\n 'antibusi',\n 'sentiment',\n 'among',\n 'the',\n 'protest',\n 'the',\n 'threat',\n 'of',\n 'more',\n 'violenc',\n 'pose',\n 'a',\n 'secur',\n 'nightmar',\n 'for',\n 'the',\n 'author',\n 'who',\n 'make',\n 'a',\n 'distinct',\n 'between',\n 'the',\n 'peac',\n 'gilet',\n 'jaun',\n 'protest',\n 'and',\n 'violent',\n 'group',\n 'anarchist',\n 'and',\n 'looter',\n 'from',\n 'the',\n 'depriv',\n 'suburb',\n 'who',\n 'they',\n 'say',\n 'have',\n 'infiltr',\n 'the',\n 'movement',\n 'on',\n 'facebook',\n 'group',\n 'and',\n 'across',\n 'social',\n 'media',\n 'the',\n 'gilet',\n 'jaun',\n 'are',\n 'call',\n 'for',\n 'an',\n 'act',\n 'a',\n 'refer',\n 'to',\n 'what',\n 'would',\n 'be',\n 'a',\n 'fourth',\n 'weekend',\n 'of',\n 'disord',\n 'franc',\n 'is',\n 'fed',\n 'up',\n 'we',\n 'will',\n 'be',\n 'there',\n 'in',\n 'bigger',\n 'number',\n 'stronger',\n 'stand',\n 'up',\n 'for',\n 'french',\n 'peopl',\n 'meet',\n 'in',\n 'pari',\n 'on',\n 'dec',\n 'said',\n 'one',\n 'group',\n 'banner',\n 'the',\n 'educ',\n 'minist',\n 'jeanmichel',\n 'blanquer',\n 'urg',\n 'peopl',\n 'to',\n 'stay',\n 'at',\n 'home',\n 'thi',\n 'weekend',\n 'secur',\n 'sourc',\n 'said',\n 'the',\n 'govern',\n 'wa',\n 'consid',\n 'use',\n 'troop',\n 'current',\n 'deploy',\n 'on',\n 'antiterror',\n 'patrol',\n 'to',\n 'protect',\n 'public',\n 'build',\n 'the',\n 'protest',\n 'name',\n 'after',\n 'the',\n 'fluoresc',\n 'jacket',\n 'french',\n 'motorist',\n 'are',\n 'requir',\n 'to',\n 'keep',\n 'in',\n 'their',\n 'car',\n 'erupt',\n 'in',\n 'novemb',\n 'over',\n 'the',\n 'squeez',\n 'on',\n 'household',\n 'budget',\n 'caus',\n 'by',\n 'fuel',\n 'tax',\n 'demonstr',\n 'swiftli',\n 'grew',\n 'into',\n 'a',\n 'broad',\n 'sometim',\n 'violent',\n 'rebellion',\n 'against',\n 'macron',\n 'who',\n 'are',\n 'the',\n 'gilet',\n 'jaun',\n 'and',\n 'what',\n 'do',\n 'they',\n 'want',\n 'read',\n 'more',\n 'the',\n 'protest',\n 'have',\n 'no',\n 'formal',\n 'leader',\n 'and',\n 'their',\n 'demand',\n 'are',\n 'divers',\n 'they',\n 'includ',\n 'chang',\n 'to',\n 'a',\n 'tax',\n 'system',\n 'perceiv',\n 'as',\n 'unfair',\n 'and',\n 'unjust',\n 'higher',\n 'salari',\n 'and',\n 'macron',\n 'resign',\n 'franc',\n 'hardleft',\n 'cgt',\n 'trade',\n 'union',\n 'on',\n 'thursday',\n 'call',\n 'on',\n 'it',\n 'energi',\n 'industri',\n 'worker',\n 'to',\n 'walk',\n 'out',\n 'for',\n 'hour',\n 'from',\n 'decemb',\n 'say',\n 'it',\n 'want',\n 'to',\n 'join',\n 'forc',\n 'with',\n 'the',\n 'gilet',\n 'jaun',\n 'the',\n 'fuel',\n 'tax',\n 'voltefac',\n 'wa',\n 'the',\n 'first',\n 'major',\n 'uturn',\n 'of',\n 'macron',\n 'month',\n 'presid',\n 'the',\n 'unrest',\n 'ha',\n 'expos',\n 'deepseat',\n 'resent',\n 'among',\n 'nonciti',\n 'dweller',\n 'with',\n 'a',\n 'percept',\n 'that',\n 'macron',\n 'is',\n 'out',\n 'of',\n 'touch',\n 'with',\n 'the',\n 'middl',\n 'and',\n 'work',\n 'class',\n 'they',\n 'see',\n 'the',\n 'yearold',\n 'former',\n 'invest',\n 'banker',\n 'as',\n 'closer',\n 'to',\n 'big',\n 'busi',\n 'and',\n 'the',\n 'rich',\n 'troubl',\n 'is',\n 'also',\n 'brew',\n 'elsewher',\n 'for',\n 'macron',\n 'teenag',\n 'student',\n 'block',\n 'access',\n 'to',\n 'more',\n 'than',\n 'high',\n 'school',\n 'across',\n 'the',\n 'countri',\n 'on',\n 'thursday',\n 'burn',\n 'garbag',\n 'bin',\n 'and',\n 'set',\n 'a',\n 'car',\n 'alight',\n 'in',\n 'the',\n 'western',\n 'citi',\n 'of',\n 'nant',\n 'farmer',\n 'who',\n 'have',\n 'long',\n 'complain',\n 'that',\n 'retail',\n 'are',\n 'squeez',\n 'their',\n 'margin',\n 'and',\n 'are',\n 'furiou',\n 'over',\n 'a',\n 'delay',\n 'to',\n 'the',\n 'plan',\n 'rise',\n 'in',\n 'minimum',\n 'food',\n 'price',\n 'and',\n 'trucker',\n 'are',\n 'threaten',\n 'to',\n 'strike',\n 'from',\n 'sunday',\n 'le',\n 'mair',\n 'said',\n 'franc',\n 'wa',\n 'no',\n 'longer',\n 'spare',\n 'from',\n 'the',\n 'wave',\n 'of',\n 'popul',\n 'that',\n 'had',\n 'swept',\n 'across',\n 'europ',\n 'it',\n 'onli',\n 'that',\n 'in',\n 'franc',\n 'it',\n 'not',\n 'manifest',\n 'itself',\n 'at',\n 'the',\n 'ballot',\n 'box',\n 'but',\n 'in',\n 'the',\n 'streetssfranc',\n 'is',\n 'brace',\n 'for',\n 'yet',\n 'anoth',\n 'weekend',\n 'of',\n 'protest',\n 'that',\n 'could',\n 'rock',\n 'pari',\n 'and',\n 'other',\n 'part',\n 'of',\n 'the',\n 'countri',\n 'prime',\n 'minist',\n 'edouard',\n 'philipp',\n 'said',\n 'the',\n 'govern',\n 'wa',\n 'deploy',\n 'secur',\n 'forc',\n 'member',\n 'across',\n 'franc',\n 'includ',\n 'in',\n 'the',\n 'capit',\n 'in',\n 'case',\n 'the',\n 'demonstr',\n 'turn',\n 'violent',\n 'again',\n 'mani',\n 'of',\n 'the',\n 'capit',\n 'fame',\n 'site',\n 'includ',\n 'the',\n 'louvr',\n 'the',\n 'eiffel',\n 'tower',\n 'the',\n 'muse',\n 'delacroix',\n 'and',\n 'the',\n 'pari',\n 'opera',\n 'will',\n 'close',\n 'over',\n 'the',\n 'weekend',\n 'in',\n 'advanc',\n 'of',\n 'the',\n 'protest',\n 'organ',\n 'by',\n 'the',\n 'gilet',\n 'jaun',\n 'or',\n 'yellow',\n 'vest',\n 'movement',\n 'their',\n 'name',\n 'come',\n 'from',\n 'the',\n 'highvis',\n 'yellow',\n 'vest',\n 'that',\n 'driver',\n 'are',\n 'requir',\n 'to',\n 'keep',\n 'in',\n 'their',\n 'vehicl',\n 'for',\n 'safeti',\n 'reason',\n 'interior',\n 'minist',\n 'christoph',\n 'castan',\n 'vow',\n 'to',\n 'deploy',\n 'all',\n 'the',\n 'mean',\n 'avail',\n 'to',\n 'ensur',\n 'the',\n 'latest',\n 'yellow',\n 'vest',\n 'protest',\n 'are',\n 'not',\n 'hijack',\n 'by',\n 'what',\n 'he',\n 'said',\n 'were',\n 'peopl',\n 'a',\n 'small',\n 'minor',\n 'of',\n 'the',\n 'movement',\n 'who',\n 'have',\n 'been',\n 'radic',\n 'and',\n 'fallen',\n 'into',\n 'violenc',\n 'and',\n 'hate',\n 'we',\n 'have',\n 'to',\n 'guarante',\n 'the',\n 'safeti',\n 'of',\n 'protest',\n 'and',\n 'the',\n 'right',\n 'of',\n 'citizen',\n 'to',\n 'move',\n 'around',\n 'freeli',\n 'castan',\n 'told',\n 'a',\n 'news',\n 'confer',\n 'friday',\n 'store',\n 'along',\n 'the',\n 'capit',\n 'fame',\n 'champ',\n 'elyse',\n 'avenu',\n 'have',\n 'also',\n 'been',\n 'advis',\n 'to',\n 'remain',\n 'shut',\n 'thi',\n 'weekend',\n 'mani',\n 'shop',\n 'owner',\n 'were',\n 'board',\n 'up',\n 'their',\n 'store',\n 'on',\n 'friday',\n 'amid',\n 'fear',\n 'of',\n 'further',\n 'disord',\n 'the',\n 'french',\n 'retail',\n 'sector',\n 'ha',\n 'suffer',\n 'a',\n 'loss',\n 'in',\n 'revenu',\n 'of',\n 'about',\n 'billion',\n 'sinc',\n 'the',\n 'begin',\n 'of',\n 'the',\n 'yellow',\n 'vest',\n 'protest',\n 'last',\n 'month',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"queries= [\n    \"Three bombings kill at least 17 people in Baghdad.\",\n    \"Fires in Indonesia burn and blow smoke into Singapore, engulfing the city-state into darkness.\",\n    \"At least 80 Shia pilgrims are killed in a truck bomb attack in Iraq. Islamic State of Iraq and the Levant claims responsibility.\",\n    \"Voters in Austria go to the polls to elect a new President in a second round run-off between Green candidate Alexander Van der Bellen and Freedom Party of Austria candidate Norbert Hofer. Projections show that Van der Bellen has won with Hofer conceding defeat.\",\n    \"The U.S. Supreme Court upholds an appeals court decision in an insider trading case, Salman v. U.S., holding that there is no requirement that a tipper receive any pecuniary consideration for a breach of faith in order to predicate the prosecution of the tippee.\",\n    \"Colombian President Juan Manuel Santos and FARC guerrilla leader Rodrigo Londo√±o, also known as Timochenko, sign a peace accord in Cartagena, ending the longest running armed conflict in the Western Hemisphere. The final agreement will be submitted to popular ratification in a referendum on October 2.\",\n    \"A gunman shoot dead a policemen in Cairo.\",\n    \"The New York City Metropolitan Opera cancels its Saturday performances as a man, during an afternoon intermission, sprinkled an unidentified powder, suspected to be cremated ashes, into the orchestra pit. One person was exposed and requested medical attention.\",\n    \"Iran releases Canadian-Iranian sociocultural anthropologist Homa Hoodfar, who had been held since June, as the countries begin talks on restoration of diplomatic ties.\",\n    \"Elections are held in The Gambia.\",\n]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:17:41.818742Z","iopub.execute_input":"2024-09-14T09:17:41.819292Z","iopub.status.idle":"2024-09-14T09:17:41.826971Z","shell.execute_reply.started":"2024-09-14T09:17:41.819242Z","shell.execute_reply":"2024-09-14T09:17:41.825610Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"preprocessed_queries = [preprocess_document(query) for query in queries]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:17:42.478078Z","iopub.execute_input":"2024-09-14T09:17:42.478528Z","iopub.status.idle":"2024-09-14T09:17:42.497506Z","shell.execute_reply.started":"2024-09-14T09:17:42.478485Z","shell.execute_reply":"2024-09-14T09:17:42.496071Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"preprocessed_queries","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:17:43.767164Z","iopub.execute_input":"2024-09-14T09:17:43.768184Z","iopub.status.idle":"2024-09-14T09:17:43.782007Z","shell.execute_reply.started":"2024-09-14T09:17:43.768119Z","shell.execute_reply":"2024-09-14T09:17:43.780726Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[['three', 'bomb', 'kill', 'at', 'least', 'peopl', 'in', 'baghdad'],\n ['fire',\n  'in',\n  'indonesia',\n  'burn',\n  'and',\n  'blow',\n  'smoke',\n  'into',\n  'singapor',\n  'engulf',\n  'the',\n  'cityst',\n  'into',\n  'dark'],\n ['at',\n  'least',\n  'shia',\n  'pilgrim',\n  'are',\n  'kill',\n  'in',\n  'a',\n  'truck',\n  'bomb',\n  'attack',\n  'in',\n  'iraq',\n  'islam',\n  'state',\n  'of',\n  'iraq',\n  'and',\n  'the',\n  'levant',\n  'claim',\n  'respons'],\n ['voter',\n  'in',\n  'austria',\n  'go',\n  'to',\n  'the',\n  'poll',\n  'to',\n  'elect',\n  'a',\n  'new',\n  'presid',\n  'in',\n  'a',\n  'second',\n  'round',\n  'runoff',\n  'between',\n  'green',\n  'candid',\n  'alexand',\n  'van',\n  'der',\n  'bellen',\n  'and',\n  'freedom',\n  'parti',\n  'of',\n  'austria',\n  'candid',\n  'norbert',\n  'hofer',\n  'project',\n  'show',\n  'that',\n  'van',\n  'der',\n  'bellen',\n  'ha',\n  'won',\n  'with',\n  'hofer',\n  'conced',\n  'defeat'],\n ['the',\n  'us',\n  'suprem',\n  'court',\n  'uphold',\n  'an',\n  'appeal',\n  'court',\n  'decis',\n  'in',\n  'an',\n  'insid',\n  'trade',\n  'case',\n  'salman',\n  'v',\n  'us',\n  'hold',\n  'that',\n  'there',\n  'is',\n  'no',\n  'requir',\n  'that',\n  'a',\n  'tipper',\n  'receiv',\n  'ani',\n  'pecuniari',\n  'consider',\n  'for',\n  'a',\n  'breach',\n  'of',\n  'faith',\n  'in',\n  'order',\n  'to',\n  'predic',\n  'the',\n  'prosecut',\n  'of',\n  'the',\n  'tippe'],\n ['colombian',\n  'presid',\n  'juan',\n  'manuel',\n  'santo',\n  'and',\n  'farc',\n  'guerrilla',\n  'leader',\n  'rodrigo',\n  'londoo',\n  'also',\n  'known',\n  'as',\n  'timochenko',\n  'sign',\n  'a',\n  'peac',\n  'accord',\n  'in',\n  'cartagena',\n  'end',\n  'the',\n  'longest',\n  'run',\n  'arm',\n  'conflict',\n  'in',\n  'the',\n  'western',\n  'hemispher',\n  'the',\n  'final',\n  'agreement',\n  'will',\n  'be',\n  'submit',\n  'to',\n  'popular',\n  'ratif',\n  'in',\n  'a',\n  'referendum',\n  'on',\n  'octob'],\n ['a', 'gunman', 'shoot', 'dead', 'a', 'policemen', 'in', 'cairo'],\n ['the',\n  'new',\n  'york',\n  'citi',\n  'metropolitan',\n  'opera',\n  'cancel',\n  'it',\n  'saturday',\n  'perform',\n  'as',\n  'a',\n  'man',\n  'dure',\n  'an',\n  'afternoon',\n  'intermiss',\n  'sprinkl',\n  'an',\n  'unidentifi',\n  'powder',\n  'suspect',\n  'to',\n  'be',\n  'cremat',\n  'ash',\n  'into',\n  'the',\n  'orchestra',\n  'pit',\n  'one',\n  'person',\n  'wa',\n  'expos',\n  'and',\n  'request',\n  'medic',\n  'attent'],\n ['iran',\n  'releas',\n  'canadianiranian',\n  'sociocultur',\n  'anthropologist',\n  'homa',\n  'hoodfar',\n  'who',\n  'had',\n  'been',\n  'held',\n  'sinc',\n  'june',\n  'as',\n  'the',\n  'countri',\n  'begin',\n  'talk',\n  'on',\n  'restor',\n  'of',\n  'diplomat',\n  'tie'],\n ['elect', 'are', 'held', 'in', 'the', 'gambia']]"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_documents_from_directory(directory_path):\n    preprocessed_docs = []\n    \n    # Loop through all the files in the directory\n    for filename in os.listdir(directory_path):\n        file_path = os.path.join(directory_path, filename)\n        \n        # Check if it's a file (ignore directories)\n        if os.path.isfile(file_path):\n            with open(file_path, 'r', encoding='utf-8') as file:\n                text = file.read()\n                preprocessed_text = text\n                \n                # Store the preprocessed tokens using the filename as key\n                preprocessed_docs.append(preprocessed_text)\n    \n    return preprocessed_docs\n\n\ndocuments = preprocess_documents_from_directory(directory_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:17:47.709147Z","iopub.execute_input":"2024-09-14T09:17:47.709679Z","iopub.status.idle":"2024-09-14T09:18:04.748908Z","shell.execute_reply.started":"2024-09-14T09:17:47.709630Z","shell.execute_reply":"2024-09-14T09:18:04.747250Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.stem import PorterStemmer\nfrom joblib import Parallel, delayed\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize the Porter stemmer once\nstemmer = PorterStemmer()\n\ndef custom_preprocessor(text):\n    # Remove special characters, punctuation, and digits\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n    \n    # Convert to lowercase and split into words\n    words = text.lower().split()\n    \n    # Apply stemming to each word\n    stemmed_words = [stemmer.stem(word) for word in words]\n    \n    # Join stemmed words back into a single string\n    return ' '.join(stemmed_words)\n\n# Initialize TfidfVectorizer without custom preprocessing\nvectorizer = TfidfVectorizer(stop_words=None, preprocessor=custom_preprocessor)\n\n# Fit and transform the processed documents\ntfidf_matrix = vectorizer.fit_transform(documents)\n\n# Convert the sparse matrix to a dense matrix for readability\nprint(tfidf_matrix.toarray())\n\n# Print the feature names\nprint(vectorizer.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:18:04.751358Z","iopub.execute_input":"2024-09-14T09:18:04.751760Z","iopub.status.idle":"2024-09-14T09:34:14.810840Z","shell.execute_reply.started":"2024-09-14T09:18:04.751716Z","shell.execute_reply":"2024-09-14T09:34:14.809300Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n['aa' 'aaa' 'aaaa' ... 'zypri' 'zyuganov' 'zzzof']\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidf_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:34:14.813395Z","iopub.execute_input":"2024-09-14T09:34:14.813965Z","iopub.status.idle":"2024-09-14T09:34:14.824676Z","shell.execute_reply.started":"2024-09-14T09:34:14.813904Z","shell.execute_reply":"2024-09-14T09:34:14.823303Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(7584, 223150)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install rank_bm25","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:04:15.159146Z","iopub.execute_input":"2024-09-14T10:04:15.159671Z","iopub.status.idle":"2024-09-14T10:04:31.696600Z","shell.execute_reply.started":"2024-09-14T10:04:15.159626Z","shell.execute_reply":"2024-09-14T10:04:31.694951Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Collecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rank_bm25) (1.26.4)\nDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nInstalling collected packages: rank_bm25\nSuccessfully installed rank_bm25-0.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from rank_bm25 import BM25Okapi\nimport numpy as np\n\n# Initialize the BM25 model with the documents\nbm25 = BM25Okapi(preprocessed_documents)\n\n# Initialize a matrix to hold the BM25 scores\nbm25_matrix = np.zeros((len(preprocessed_documents), len(preprocessed_queries)))\n\n# Calculate BM25 score for each document-query pair\nfor i, query in enumerate(preprocessed_queries):\n    query_scores = bm25.get_scores(query)\n    bm25_matrix[:, i] = query_scores","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:17:06.475296Z","iopub.execute_input":"2024-09-14T10:17:06.475815Z","iopub.status.idle":"2024-09-14T10:17:19.731328Z","shell.execute_reply.started":"2024-09-14T10:17:06.475767Z","shell.execute_reply":"2024-09-14T10:17:19.729842Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"bm25_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:17:19.733341Z","iopub.execute_input":"2024-09-14T10:17:19.733786Z","iopub.status.idle":"2024-09-14T10:17:19.742138Z","shell.execute_reply.started":"2024-09-14T10:17:19.733737Z","shell.execute_reply":"2024-09-14T10:17:19.740584Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"(7584, 10)"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\n# Function to get top p stems from the corpus\ndef get_top_stems(documents, p):\n    # Initialize a Counter to accumulate frequencies of stems\n    stem_counter = Counter()\n    \n    # Iterate through each document and accumulate stem counts\n    for document in documents:\n        # Tokenize each document (assuming it's preprocessed and stemmed)\n        stems = document\n        stem_counter.update(stems)  # Update counter with stems from the document\n    \n    # Get the top p stems based on frequency and return only the stems (not counts)\n    top_stems = [stem for stem, _ in stem_counter.most_common(p)]\n    \n    return top_stems\n\np = 6\n\n# Get top 5 stems from the corpus\ntop_stems = get_top_stems(preprocessed_documents, p)\n\n# Print the top stems\nprint(top_stems)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:34:34.831482Z","iopub.execute_input":"2024-09-14T09:34:34.831929Z","iopub.status.idle":"2024-09-14T09:34:40.450357Z","shell.execute_reply.started":"2024-09-14T09:34:34.831883Z","shell.execute_reply":"2024-09-14T09:34:40.448925Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"['the', 'of', 'to', 'in', 'and', 'a']\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Function to create binary vectors for documents based on top stems\ndef create_binary_vectors(documents, top_stems):\n    # Initialize binary matrix\n    num_docs = len(documents)\n    num_stems = len(top_stems)\n    binary_matrix = np.zeros((num_docs, num_stems), dtype=int)\n    \n    # Create a dictionary to map stems to column indices\n    stem_index = {stem: idx for idx, stem in enumerate(top_stems)}\n    \n    for i, document in enumerate(documents):\n        # Get the set of stems present in the document\n        present_stems = set(document)\n        \n        for stem in present_stems:\n            if stem in stem_index:\n                col = stem_index[stem]\n                binary_matrix[i, col] = 1\n    \n    return binary_matrix\n\n# Create binary vectors for the documents\ndocument_binary_vectors = create_binary_vectors(preprocessed_documents, top_stems)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:34:59.587641Z","iopub.execute_input":"2024-09-14T09:34:59.588157Z","iopub.status.idle":"2024-09-14T09:35:01.478716Z","shell.execute_reply.started":"2024-09-14T09:34:59.588047Z","shell.execute_reply":"2024-09-14T09:35:01.477190Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"query_binary_vectors = create_binary_vectors(preprocessed_queries, top_stems)\n\nprint(query_binary_vectors)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:35:02.161802Z","iopub.execute_input":"2024-09-14T09:35:02.162279Z","iopub.status.idle":"2024-09-14T09:35:02.169567Z","shell.execute_reply.started":"2024-09-14T09:35:02.162229Z","shell.execute_reply":"2024-09-14T09:35:02.168296Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[[0 0 0 1 0 0]\n [1 0 0 1 1 0]\n [1 1 0 1 1 1]\n [1 1 1 1 1 1]\n [1 1 1 1 0 1]\n [1 0 1 1 1 1]\n [0 0 0 1 0 1]\n [1 0 1 0 1 1]\n [1 1 0 0 0 0]\n [1 0 0 1 0 0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"def dot_product(document_binary_vectors, query_binary_vectors):\n    final_list = []\n    for doc_vector in document_binary_vectors:\n        for query_vector in query_binary_vectors:\n            resultant = np.dot(doc_vector, query_vector)\n            \n            # Check if the resultant is equal to the length of the vectors|\n            if resultant == len(doc_vector):\n                final_list.append(doc_vector)\n    \n    return final_list","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:35:05.982904Z","iopub.execute_input":"2024-09-14T09:35:05.983452Z","iopub.status.idle":"2024-09-14T09:35:05.991337Z","shell.execute_reply.started":"2024-09-14T09:35:05.983385Z","shell.execute_reply":"2024-09-14T09:35:05.989689Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"final_list = dot_product(document_binary_vectors, query_binary_vectors)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:35:06.317379Z","iopub.execute_input":"2024-09-14T09:35:06.317830Z","iopub.status.idle":"2024-09-14T09:35:06.541844Z","shell.execute_reply.started":"2024-09-14T09:35:06.317786Z","shell.execute_reply":"2024-09-14T09:35:06.540502Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"len(final_list)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T09:42:24.715308Z","iopub.execute_input":"2024-09-14T09:42:24.715759Z","iopub.status.idle":"2024-09-14T09:42:24.723609Z","shell.execute_reply.started":"2024-09-14T09:42:24.715716Z","shell.execute_reply":"2024-09-14T09:42:24.722302Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"7565"},"metadata":{}}]},{"cell_type":"markdown","source":"Here we are trying to represent the queries in the space of tf-idf","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Step 1: Create the TfidfVectorizer and fit it on the documents\nvectorizer = TfidfVectorizer(stop_words=None, preprocessor=custom_preprocessor)\n\n# Fit the vectorizer on documents to create the document TF-IDF matrix\ndocument_tfidf_matrix = vectorizer.fit_transform(documents)\n\n# Step 2: Use the same vectorizer to transform the queries into the same space\nquery_tfidf_matrix = vectorizer.transform(queries)\n\n# Step 3: Convert both matrices to dense format for readability (optional)\ndocument_tfidf_dense = document_tfidf_matrix.toarray()\nquery_tfidf_dense = query_tfidf_matrix.toarray()\n\n# Print the resulting TF-IDF matrices\nprint(\"Document TF-IDF Matrix:\")\nprint(document_tfidf_dense)\n\nprint(\"Query TF-IDF Matrix (in document space):\")\nprint(query_tfidf_dense)\n\n# Step 4: Print the feature names (vocabulary)\nprint(\"Vocabulary (Feature Names):\")\nprint(vectorizer.get_feature_names_out())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:33:57.492950Z","iopub.execute_input":"2024-09-14T10:33:57.493502Z","iopub.status.idle":"2024-09-14T10:50:25.950889Z","shell.execute_reply.started":"2024-09-14T10:33:57.493450Z","shell.execute_reply":"2024-09-14T10:50:25.949405Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Document TF-IDF Matrix:\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\nQuery TF-IDF Matrix (in document space):\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\nVocabulary (Feature Names):\n['aa' 'aaa' 'aaaa' ... 'zypri' 'zyuganov' 'zzzof']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(document_tfidf_dense.shape, query_tfidf_dense.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:50:25.952970Z","iopub.execute_input":"2024-09-14T10:50:25.953415Z","iopub.status.idle":"2024-09-14T10:50:25.960584Z","shell.execute_reply.started":"2024-09-14T10:50:25.953370Z","shell.execute_reply":"2024-09-14T10:50:25.959300Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"(7584, 223150) (10, 223150)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize the BM25 model with the queries as documents\nbm25 = BM25Okapi(preprocessed_queries)\n\n# Initialize a matrix to hold BM25 scores between queries\nnum_queries = 10\nbm25_query_matrix = np.zeros((num_queries, num_queries))\n\n# Calculate BM25 scores between each pair of queries\nfor i in range(num_queries):\n    for j in range(num_queries):\n        # Compute BM25 score between query i and query j\n        score = bm25.get_scores(preprocessed_queries[j])[i]  # BM25 score of query j with respect to query i\n        bm25_query_matrix[i][j] = score\n\n# Print the resulting BM25 query-query matrix\nprint(\"BM25 Query-Query Matrix:\")\nprint(bm25_query_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:50:53.168782Z","iopub.execute_input":"2024-09-14T10:50:53.169329Z","iopub.status.idle":"2024-09-14T10:50:53.250942Z","shell.execute_reply.started":"2024-09-14T10:50:53.169278Z","shell.execute_reply":"2024-09-14T10:50:53.249067Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"BM25 Query-Query Matrix:\n[[15.67683812  0.61950357  8.30410241  1.23900714  1.23900714  1.85851071\n   0.61950357  0.          0.          0.61950357]\n [ 0.53653434 25.91787039  1.60960302  1.60960302  2.6826717   3.21920604\n   0.53653434  3.1126944   0.53653434  1.07306868]\n [ 5.83104952  1.09451622 32.1862237   3.03428482  4.33477847  4.19403117\n   1.54975748  1.36572378  0.84525239  2.39245986]\n [ 0.4945831   0.81592987  2.08039803 58.86588102  5.74908346  4.7768671\n   1.48374929  2.47718794  0.59664875  1.73212538]\n [ 0.4945831   1.09751132  2.51039331  4.96569196 54.98727173  4.55700212\n   1.48374929  4.79596473  1.02664402  1.09751132]\n [ 0.59792882  1.19585763  2.28333306  4.22032821  4.24040733 50.38753469\n   1.57702203  3.42424138  2.06509593  1.19585763]\n [ 0.61950357  0.61950357  2.02452147  2.81003579  2.81003579  3.42953936\n  15.51093102  0.78551433  0.          0.61950357]\n [ 0.          2.51931402  0.87649266  2.82058187  5.58518186  4.19586047\n   0.6987424  48.88258559  1.14746801  0.52712146]\n [ 0.          0.44677953  0.82954138  0.82954138  2.10586228  3.4074625\n   0.          1.68686468 38.75400226  1.72059782]\n [ 0.65317224  1.30634448  3.82178368  3.82178368  3.2658612   3.91903344\n   0.65317224  1.30634448  2.5154392   9.70201207]]\n","output_type":"stream"}]},{"cell_type":"code","source":"bm25_query_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:51:09.815956Z","iopub.execute_input":"2024-09-14T10:51:09.816508Z","iopub.status.idle":"2024-09-14T10:51:09.826161Z","shell.execute_reply.started":"2024-09-14T10:51:09.816462Z","shell.execute_reply":"2024-09-14T10:51:09.824672Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"(10, 10)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Compute cosine similarity between each document vector and each query vector\nsimilarity_matrix_tfidf = cosine_similarity(document_tfidf_dense, query_tfidf_dense)\n\n# Print the similarity matrix (documents x queries)\nprint(\"Cosine Similarity Matrix (Documents x Queries) in TF-IDF Space:\")\nprint(similarity_matrix_tfidf)\n\n# Rank documents for each query based on similarity scores\nfor query_idx in range(similarity_matrix_tfidf.shape[1]):\n    # Get similarity scores for the current query\n    scores = similarity_matrix_tfidf[:, query_idx]\n    # Get indices of documents sorted by their scores (highest first)\n    ranked_doc_indices = np.argsort(scores)[::-1]\n    print(f\"Ranked Documents for Query {query_idx}: {ranked_doc_indices}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T11:03:03.755898Z","iopub.execute_input":"2024-09-14T11:03:03.757133Z","iopub.status.idle":"2024-09-14T11:03:24.659196Z","shell.execute_reply.started":"2024-09-14T11:03:03.757064Z","shell.execute_reply":"2024-09-14T11:03:24.657557Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Cosine Similarity Matrix (Documents x Queries) in TF-IDF Space:\n[[0.10362973 0.08482366 0.18336831 ... 0.08498604 0.04416203 0.10352687]\n [0.0446559  0.0789684  0.10552818 ... 0.10715943 0.04830338 0.11011781]\n [0.09129863 0.05341169 0.11187088 ... 0.06259778 0.03165063 0.07930433]\n ...\n [0.05195917 0.0638894  0.10245791 ... 0.07349316 0.04171289 0.09244985]\n [0.03811585 0.04695934 0.06926042 ... 0.06209403 0.03297577 0.07358835]\n [0.02111262 0.05797915 0.06917933 ... 0.06151117 0.03107286 0.06807464]]\nRanked Documents for Query 0: [3167 7558 1357 ... 3676 5465 7571]\nRanked Documents for Query 1: [3937 2765  338 ...  660 3130 7571]\nRanked Documents for Query 2: [1847 7558 2425 ... 5465 7571 3130]\nRanked Documents for Query 3: [ 750 5578 5421 ... 6016 3130  660]\nRanked Documents for Query 4: [4105 7201 4353 ...  660 3130 5465]\nRanked Documents for Query 5: [4558  334 6349 ... 5465  660 7571]\nRanked Documents for Query 6: [4314 4628 5871 ... 5932 1532 3676]\nRanked Documents for Query 7: [4184  646 2862 ...  660 3130 1297]\nRanked Documents for Query 8: [6504 7319 6494 ... 7571 3130  660]\nRanked Documents for Query 9: [4791 1152 3094 ...  660 3130 7571]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import normalize\n\n# Normalize BM25 matrices\nbm25_normalized_docs = normalize(bm25_matrix, norm='l2')\nbm25_normalized_queries = normalize(bm25_query_matrix, norm='l2')\n\n# Compute cosine similarity between each document vector and each query vector\nsimilarity_matrix_bm25 = cosine_similarity(bm25_normalized_docs, bm25_normalized_queries)\n\n# Print the similarity matrix (documents x queries)\nprint(\"Cosine Similarity Matrix (Documents x Queries) in BM25 Space:\")\nprint(similarity_matrix_bm25)\n\n# Rank documents for each query based on similarity scores\nfor query_idx in range(similarity_matrix_bm25.shape[1]):\n    # Get similarity scores for the current query\n    scores = similarity_matrix_bm25[:, query_idx]\n    # Get indices of documents sorted by their scores (highest first)\n    ranked_doc_indices = np.argsort(scores)[::-1]\n    print(f\"Ranked Documents for Query {query_idx}: {ranked_doc_indices}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T11:04:32.436269Z","iopub.execute_input":"2024-09-14T11:04:32.436868Z","iopub.status.idle":"2024-09-14T11:04:32.468603Z","shell.execute_reply.started":"2024-09-14T11:04:32.436814Z","shell.execute_reply":"2024-09-14T11:04:32.467039Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Cosine Similarity Matrix (Documents x Queries) in BM25 Space:\n[[0.43872906 0.36390719 0.60319032 ... 0.55489743 0.29671242 0.65642687]\n [0.34204699 0.3436356  0.45698908 ... 0.59445786 0.32450536 0.6461111 ]\n [0.37739486 0.32864522 0.50975692 ... 0.55567585 0.33494146 0.66380504]\n ...\n [0.36335819 0.33448334 0.49432931 ... 0.54771639 0.29787318 0.65621043]\n [0.33309758 0.32203335 0.47136014 ... 0.52480915 0.33547265 0.65566982]\n [0.31234862 0.36840436 0.45080504 ... 0.54908924 0.30068659 0.65106512]]\nRanked Documents for Query 0: [4754 5927 7558 ... 7571 5465 4184]\nRanked Documents for Query 1: [3937 5065 6637 ... 3130  750 7571]\nRanked Documents for Query 2: [4893 2425 7558 ... 5465  750 4184]\nRanked Documents for Query 3: [ 750 4742 7571 ... 3482 4105 4184]\nRanked Documents for Query 4: [4105 6016 5951 ...  334 6349  750]\nRanked Documents for Query 5: [ 334 6349   24 ... 7571  750 4184]\nRanked Documents for Query 6: [ 660 1297 3130 ... 5932 3482 4184]\nRanked Documents for Query 7: [4184 3047 5027 ...  660 3130 1297]\nRanked Documents for Query 8: [6504 3482 3635 ... 7571 3130  660]\nRanked Documents for Query 9: [2101 2104 5870 ... 4105 7571 4184]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}